{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "What are the available fields?\n",
    "\n",
    "There's no \"description\" or \"plot summary\" of movies.\n",
    "So one must look at all the dialogs and decipher the movie genre?\n",
    "\n",
    "How can we do this?\n",
    "Let's do this in a naive way first, then let's try to get creative.\n",
    "\n",
    "---\n",
    "\n",
    "Destruction of the data:\n",
    "- movies\n",
    "    - conversations\n",
    "        - dialogs\n",
    "            - sentences\n",
    "                - words\n",
    "\n",
    "---\n",
    "\n",
    "## Naive way:\n",
    "\n",
    "- Average all word embeddings in a dialog to get dialog embeddings.\n",
    "- Average all dialog embeddings to get movie plot embedding.\n",
    "\n",
    "Thought process:\n",
    "  - We get a sentence embedding by averaging the word embeddings\n",
    "  - In the same way, can we get \"scene\" embedding by averaging all the sentence embeddings in a scene?\n",
    "  - Then averaging all scene embeddings should give us movie embedding.\n",
    "  - We don't have scenes, do we? If not, we can skip scenes, will averaging all dialog embeddings give us movie embedding?\n",
    "\n",
    "Problems:\n",
    "\n",
    "- The conversations might mostly include \"everyday lines\" that do not relate to the plot.\n",
    "- For example, \"You must learn how to lie\", \"they have to!\" do not say anything about the plot.\n",
    "\n",
    "## Another method:\n",
    "\n",
    "- Find all named entities (of some relevant category).\n",
    "- Then get the dialogs with named entities only.\n",
    "- Assumption: dialogs with named entities will contain plot-related information.\n",
    "-\n",
    "\n",
    "---\n",
    "\n",
    "## Rule-based method for baseline.\n",
    "\n",
    "For each genre, what are the most used words? (after removing the stopwords)\n",
    "How many of these words occur for multiple movies?\n",
    "\n",
    "Intuitive rationale:\n",
    "\n",
    "- [Within one genre] a genre-defining word will likely have high frequency in a movie and among all movies of the same genre.\n",
    "- [Among genres] a genre-defining word will likely have high frequency in movies within the genre and low frequency among movies of other genres.\n",
    "\n",
    "This can be obtained by finding the tf-idf value for each word in the corpus.\n",
    "\n",
    "If frequency of a word is low among movies of the same genre, then it is likely not genre-defining.\n",
    "\n",
    "Assuming that we obtained these \"genre-defining\" words for each genre,\n",
    "the next task would be to somehow learn that these words (or similar words) will help predict the movie's genre.\n",
    "\n",
    "### Implementation:\n",
    "\n",
    "1. Parse all the data.\n",
    "2. store all the genres.\n",
    "3. Split 95:5 of the movies randomly (less data problem!)\n",
    "4. Find tf-idf of each word in the training set. document = genre.\n",
    "5. Can these be custom named entities?\n",
    "\n",
    "Part 1:\n",
    "\n",
    "Well, we need lines for each genre. We don't care about the \"sequential\" nature of dialogs. Just need all of them.\n",
    "\n",
    "Specifically, we need a structure like this:\n",
    "\n",
    "- genres\n",
    "    - movies\n",
    "        - words\n",
    "\n",
    "Here words are obtained by:\n",
    "\n",
    "- spaCy tokenize each dialog.\n",
    "- spaCy lemmatize\n",
    "- spaCy remove stopwords\n",
    "\n",
    "Note that a movie can have multiple genres. So the dialogs for two genres might repeat.\n",
    "\n",
    "Part 2:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Extracting all information about a movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "from contextlib import contextmanager\n",
    "from copy import deepcopy\n",
    "from os import listdir, makedirs\n",
    "from os.path import join\n",
    "from typing import List, Tuple, Dict, Optional, TextIO\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "import heapq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "class Movie(BaseModel):\n",
    "    id: str\n",
    "    title: str\n",
    "    release_year: int\n",
    "    imdb_rating: float\n",
    "    num_votes: int\n",
    "    genres: List[str] = []\n",
    "    characters: dict = {}\n",
    "    conversations: list = []\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    id: str\n",
    "    gender: Optional[str]  # m|f|None\n",
    "    credit_position: Optional[int]\n",
    "    movie: Movie\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "\n",
    "\n",
    "class Dialog(BaseModel):\n",
    "    id: str\n",
    "    speaker: Character\n",
    "    listener: Optional[Character]\n",
    "    dialog: str\n",
    "\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    characters: Tuple[Character, Character]\n",
    "    dialogs: List[Dialog]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def update_movie_characters(movies: Dict[str, Movie], characters_path: str):\n",
    "    with open(characters_path, \"r\", encoding=\"ISO-8859-1\") as characters_file:\n",
    "        for character in characters_file:\n",
    "            # sample: u0 +++$+++ BIANCA +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ f +++$+++ 4\n",
    "            character = character.strip().split(\" +++$+++ \")\n",
    "            character_id, name, movie_id, movie_title, gender, position = character\n",
    "\n",
    "            gender = None if gender == \"?\" else gender\n",
    "            position = None if position == \"?\" else position\n",
    "\n",
    "            assert movie_id in movies\n",
    "            movie = movies[movie_id]\n",
    "\n",
    "            character = Character(\n",
    "                name=name,\n",
    "                id=character_id,\n",
    "                gender=gender,  # m|f|None\n",
    "                credit_position=position,\n",
    "                movie=movie,\n",
    "            )\n",
    "\n",
    "            movie.characters[character_id] = character\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def get_all_dialogs(movies: Dict[str, Movie], lines_path: str) -> Dict[str, Dialog]:\n",
    "    all_dialogs = {}\n",
    "    with open(lines_path, \"r\", encoding=\"ISO-8859-1\") as dialogs_file:\n",
    "        for dialog in dialogs_file:\n",
    "            # Sample: L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
    "            # Note: Sometimes, there's no dialog, so splitting with ' +++$+++ ' will be wrong (with space at the end.)\n",
    "            #       So, we will split without spaces on either side and then strip\n",
    "            dialog = dialog.strip().split(\"+++$+++\")\n",
    "            dialog = [d.strip() for d in dialog]\n",
    "            dialog_id, character_id, movie_id, character_name, dialog = dialog\n",
    "\n",
    "            assert movie_id in movies\n",
    "            movie = movies[movie_id]\n",
    "\n",
    "            assert character_id in movie.characters\n",
    "            speaker = movie.characters[character_id]\n",
    "\n",
    "            dialog = Dialog(id=dialog_id, speaker=speaker, dialog=dialog)\n",
    "            all_dialogs[dialog_id] = dialog\n",
    "    return all_dialogs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "\n",
    "def update_movie_dialogs(\n",
    "    movies: Dict[str, Movie], conversations_path: str, lines_path: str\n",
    "):\n",
    "    all_dialogs: Dict[str, Dialog] = get_all_dialogs(movies, lines_path)\n",
    "\n",
    "    with open(conversations_path, \"r\", encoding=\"ISO-8859-1\") as conversations_file:\n",
    "        for conversation in conversations_file:\n",
    "            # Sample: u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
    "            conversation = conversation.strip().split(\" +++$+++ \")\n",
    "            character1, character2, movie_id, dialogs = conversation\n",
    "\n",
    "            dialogs = dialogs.strip(\"][\").replace(\"'\", \"\").split(\", \")\n",
    "\n",
    "            assert movie_id in movies\n",
    "            movie = movies[movie_id]\n",
    "\n",
    "            assert character1 in movie.characters\n",
    "            assert character2 in movie.characters\n",
    "\n",
    "            character1 = movie.characters[character1]\n",
    "            character2 = movie.characters[character2]\n",
    "\n",
    "            for dialog in dialogs:\n",
    "                assert dialog in all_dialogs\n",
    "                dialog = all_dialogs[dialog]\n",
    "                listener = character1 if character2 == dialog.speaker else character2\n",
    "                dialog.listener = listener\n",
    "\n",
    "            conversation = Conversation(\n",
    "                characters=(character1, character2),\n",
    "                dialogs=[all_dialogs[dialog] for dialog in dialogs],\n",
    "            )\n",
    "\n",
    "            movie.conversations.append(conversation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "\n",
    "def _preprocess_year(year: str) -> int:\n",
    "    if \"/I\" in year:\n",
    "        year = year.replace(\"/I\", \"\")\n",
    "    year = int(year)\n",
    "    return year\n",
    "\n",
    "\n",
    "def get_movies_dict(movie_titles_metadata_path: str) -> Dict[str, Movie]:\n",
    "    movies_dict = {}\n",
    "    with open(movie_titles_metadata_path, \"r\", encoding=\"ISO-8859-1\") as movies_file:\n",
    "        for movie in movies_file:\n",
    "            movie = movie.strip().split(\" +++$+++ \")\n",
    "            movie_id, title, year, rating, votes, genres = movie\n",
    "            # Replace list representation with list of strings\n",
    "            genres = genres.strip(\"][\").replace(\"'\", \"\").split(\", \")\n",
    "            year = _preprocess_year(year)\n",
    "            rating = float(rating)\n",
    "\n",
    "            movie = Movie(\n",
    "                id=movie_id,\n",
    "                title=title,\n",
    "                release_year=year,\n",
    "                imdb_rating=rating,\n",
    "                num_votes=votes,\n",
    "                genres=genres,\n",
    "            )\n",
    "\n",
    "            movies_dict[movie_id] = movie\n",
    "\n",
    "    return movies_dict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "617it [00:00, 14818.83it/s]\n",
      "83097it [00:06, 12755.38it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_data(path: str):\n",
    "    files = listdir(path)\n",
    "\n",
    "    # 1. For each movie:\n",
    "    #    a. get all characters\n",
    "    #    b. get all conversations\n",
    "\n",
    "    assert \"movie_titles_metadata.txt\" in files\n",
    "    assert \"movie_characters_metadata.txt\" in files\n",
    "\n",
    "    # This will likely use more memory.\n",
    "    # movies_df = pd.read_table(\n",
    "    #     join(path, 'movie_titles_metadata.txt'),\n",
    "    #     sep=r' \\+\\+\\+\\$\\+\\+\\+ ',\n",
    "    #     encoding='ISO-8859-1',\n",
    "    #     header=None,\n",
    "    # )\n",
    "\n",
    "    movies_dict = get_movies_dict(join(path, \"movie_titles_metadata.txt\"))\n",
    "    update_movie_characters(movies_dict, join(path, \"movie_characters_metadata.txt\"))\n",
    "    update_movie_dialogs(\n",
    "        movies_dict,\n",
    "        join(path, \"movie_conversations.txt\"),\n",
    "        join(path, \"movie_lines.txt\"),\n",
    "    )\n",
    "\n",
    "    return movies_dict\n",
    "\n",
    "\n",
    "data_path = \"/Users/akhil/code/lexical_lab/companies/ginger/data/cornell\"\n",
    "movies = get_data(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['m0', 'm1', 'm2', 'm3', 'm4']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movies.keys())[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "m0 = movies['m0']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['u0', 'u1', 'u2', 'u3', 'u4']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m0.characters.keys())[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations = m0.conversations[:5]\n",
    "conversations[0].dialogs[0].dialog"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "[('drama', 320),\n ('thriller', 269),\n ('action', 168),\n ('comedy', 162),\n ('crime', 147),\n ('romance', 132),\n ('sci-fi', 120),\n ('adventure', 116),\n ('mystery', 102),\n ('horror', 99),\n ('fantasy', 78),\n ('short', 5),\n ('animation', 2),\n ('family', 1)]"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genres = [genre for _, movie in movies.items() for genre in movie.genres]\n",
    "genre_movies_count = Counter(all_genres)\n",
    "all_genres = list(set(all_genres))\n",
    "\n",
    "# Sorting by value to see which genres have the most movies.\n",
    "sorted(genre_movies_count.items(), key=lambda item: item[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-252-b83541fa1d1a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Well, there's one movie without any genre. So let's put that as 'other'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mall_genres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'other'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mall_genres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mremove\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mgenre_movies_count\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'other'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenre_movies_count\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# Well, there's one movie without any genre. So let's put that as 'other'\n",
    "all_genres.append('other')\n",
    "all_genres.remove('')\n",
    "\n",
    "genre_movies_count['other'] = genre_movies_count['']\n",
    "del genre_movies_count['']\n",
    "\n",
    "# Let's also replace '' with 'other' in all movies\n",
    "for _, movie in movies.items():\n",
    "    if '' in movie.genres:\n",
    "        movie.genres.append('other')\n",
    "        movie.genres.remove('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "# Some of the genres have very low movie count.\n",
    "# This will make the frequency based method very difficult.\n",
    "# We might employ other techniques for these low-frequent genres.\n",
    "# For now, to make the problem easier, let's only use the high frequent genres only.\n",
    "\n",
    "# Eliminating all genres with frequency < 75 (75 is just based on intuition.)\n",
    "low_frequency_genres = [genre for genre in all_genres if genre_movies_count[genre] <= 75]\n",
    "\n",
    "for genre in low_frequency_genres:\n",
    "    # Remove from all_genres\n",
    "    all_genres.remove(genre)\n",
    "\n",
    "    # Remove from movie.genres\n",
    "    for _, movie in movies.items():\n",
    "        if genre in movie.genres:\n",
    "            movie.genres.remove(genre)\n",
    "\n",
    "# Remove movies with empty genres\n",
    "movies_to_remove = []\n",
    "for movie_id, movie in movies.items():\n",
    "    if len(movie.genres) == 0:\n",
    "        movies_to_remove.append(movie_id)\n",
    "for movie_id in movies_to_remove:\n",
    "    del movies[movie_id]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "# [NOT USED] Creates text files with all dialogs of each genre. NOT USED, but works.\n",
    "\n",
    "@contextmanager\n",
    "def get_genre_dialogs_files(output_path: str, genres: List[str], mode: str):\n",
    "    \"\"\"\n",
    "    A wrapper that encapsulates handling multiple genre-dialogs files.\n",
    "    \"\"\"\n",
    "    makedirs(output_path, exist_ok=True)\n",
    "    files: Dict[str, TextIO] = {genre: open(join(output_path, f'{genre}.txt'), mode) for genre in genres}\n",
    "\n",
    "    try:\n",
    "        yield files\n",
    "    finally:\n",
    "        for genre in genres:\n",
    "            files[genre].close()\n",
    "\n",
    "\n",
    "def create_genre_dialogs_files():\n",
    "    # Creating dialogs text files for each genre.\n",
    "    genre_dialogs_path = '/Users/akhil/code/lexical_lab/companies/ginger/data/output/genre_dialogs'\n",
    "    with get_genre_dialogs_files(genre_dialogs_path, all_genres, 'w') as genre_dialogs_files:\n",
    "        for _, movie in movies.items():\n",
    "            for conversation in movie.conversations:\n",
    "                for dialog in conversation.dialogs:\n",
    "                    for genre in movie.genres:\n",
    "                        genre_dialogs_files[genre].write(dialog.dialog + '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "['example', 'sentence', 'akhil', 'friends', 'cars']"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating a structure like this:\n",
    "- genres\n",
    "    - movies\n",
    "        - words\n",
    "\"\"\"\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['tok2vec', 'parser', 'ner'])\n",
    "\n",
    "def extract_words(text):\n",
    "    # Without this, there will a ' ' (space) word\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    doc = spacy_nlp(text)\n",
    "    # Words without stopwords\n",
    "    words = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return words\n",
    "\n",
    "extract_words('This is an example of  a sentence. Akhil\\'s friends have many cars')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [01:11<00:00,  8.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find word counts for each genre.\n",
    "genre_words_count = {genre: {} for genre in all_genres}\n",
    "\n",
    "for _, movie in tqdm(movies.items()):\n",
    "    dialogs = '. '.join([d.dialog for conversation in movie.conversations for d in conversation.dialogs])\n",
    "    words = extract_words(dialogs)\n",
    "    word_frequencies = Counter(words)\n",
    "\n",
    "    for genre in movie.genres:\n",
    "        for word, count in word_frequencies.items():\n",
    "            genre_word_count = genre_words_count[genre].get(word, {'movie_count': 0, 'count': 0})\n",
    "            genre_word_count['movie_count'] += 1\n",
    "            genre_word_count['count'] += count\n",
    "            genre_words_count[genre][word] = genre_word_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "# Remove words that are too infrequent.\n",
    "\n",
    "# Anything count < infrequent_threshold is removed.\n",
    "infrequent_threshold = 3\n",
    "\n",
    "# At least this % of movies should contain the genre-defining words\n",
    "infrequent_movie_threshold = 0.25\n",
    "\n",
    "for genre, words_count in genre_words_count.items():\n",
    "    words_to_remove = []\n",
    "    for word, word_count in words_count.items():\n",
    "        word_frequency = word_count['count']  # / word_count['movie_count']\n",
    "        movie_frequency = word_count['movie_count'] / genre_movies_count[genre]\n",
    "        if word_frequency < infrequent_threshold or movie_frequency < infrequent_movie_threshold:\n",
    "            words_to_remove.append(word)\n",
    "            # print(f'{word=}, {word_count=}')\n",
    "    for word in words_to_remove:\n",
    "        del words_count[word]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "data": {
      "text/plain": "1015"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building word frequency table.\n",
    "\n",
    "# all words in this frequency table\n",
    "all_words = list(set([word for word_counts in genre_words_count.values() for word in word_counts]))\n",
    "len(all_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[516, 259,   0, ...,   0, 222, 154],\n       [273, 137,   0, ...,   0, 130,  72],\n       [121,  51,   0, ...,   0,  73,  39],\n       ...,\n       [461, 132,   0, ...,   0, 131, 108],\n       [210, 104,   0, ...,   0,  89,  75],\n       [336, 154, 133, ...,   0, 131, 108]])"
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = np.zeros((len(all_genres), len(all_words)), dtype=int)\n",
    "\n",
    "for i, genre in enumerate(all_genres):\n",
    "    for j, word in enumerate(all_words):\n",
    "        if word in genre_words_count[genre]:\n",
    "            frequency = genre_words_count[genre][word]\n",
    "            frequency = frequency['count']  # / frequency['movie_count']\n",
    "            frequency_matrix[i][j] = frequency\n",
    "\n",
    "frequency_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3540, 1486,  133, ...,   52, 1390,  846])"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_genre_word_counts = frequency_matrix.sum(0)\n",
    "inter_genre_word_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.14576271, 0.17429341, 0.        , ..., 0.        , 0.15971223,\n        0.1820331 ],\n       [0.07711864, 0.09219381, 0.        , ..., 0.        , 0.09352518,\n        0.08510638],\n       [0.03418079, 0.03432032, 0.        , ..., 0.        , 0.05251799,\n        0.04609929],\n       ...,\n       [0.13022599, 0.08882907, 0.        , ..., 0.        , 0.0942446 ,\n        0.12765957],\n       [0.05932203, 0.06998654, 0.        , ..., 0.        , 0.06402878,\n        0.08865248],\n       [0.09491525, 0.10363392, 1.        , ..., 0.        , 0.0942446 ,\n        0.12765957]])"
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = frequency_matrix / inter_genre_word_counts\n",
    "tfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thriller: ['tight', 'killer', 'loose', 'department', 'address', 'split', 'fuckin', 'checked', 'key', 'cops']\n",
      "action: ['south', 'weapon', 'guard', 'sooner', 'computer', 'guns', 'weapons', 'learned', 'cross', 'orders']\n",
      "fantasy: ['trick', 'tree', 'purpose', 'opened', 'magic', 'hoping', 'feed', 'evil', 'matters', 'greatest']\n",
      "drama: ['writing', 'runs', 'accept', 'lawyer', 'agree', 'sleeping', 'decide', 'won', 'plans', 'laugh']\n",
      "romance: ['wind', 'willing', 'wild', 'train', 'sold', 'sing', 'round', 'ring', 'recognize', 'raise']\n",
      "adventure: ['sea', 'river', 'quickly', 'operation', 'north', 'lord', 'jump', 'enemy', 'continue', 'code']\n",
      "sci-fi: ['systems', 'study', 'science', 'noticed', 'nature', 'level', 'form', 'exist', 'emergency', 'data']\n",
      "horror: ['monster', 'bodies', 'locked', 'evil', 'dreams', 'danger', 'asleep', 'lock', 'radio', 'box']\n",
      "comedy: ['whoa', 'um', 'u', 'song', 'screw', 'perfectly', 'pants', 'pal', 'older', 'natural']\n",
      "mystery: ['rules', 'proof', 'murdered', 'investigation', 'held', 'forward', 'following', 'curious', 'concerned', 'tie']\n",
      "crime: ['watched', 'tape', 'steal', 'square', 'shooting', 'sees', 'scene', 'pop', 'places', 'personally']\n"
     ]
    }
   ],
   "source": [
    "# Okay, now that we have tf-idf matrix,\n",
    "# Let's find the highest ranking top k words for each genre.\n",
    "\n",
    "for i in range(len(all_genres)):\n",
    "    tfidf_ranks = tfidf[i]\n",
    "    counts = frequency_matrix[i]\n",
    "\n",
    "    zipped = zip(tfidf_ranks, all_words, counts, inter_genre_word_counts)\n",
    "    pairs = heapq.nlargest(10, zipped)\n",
    "    keywords = [pair[1] for pair in pairs]\n",
    "    print(f'{all_genres[i]}: {keywords}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "'this is a test'"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}